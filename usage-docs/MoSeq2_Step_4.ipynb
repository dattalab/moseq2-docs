{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis: Model Fitting\n",
    "\n",
    "Now that we have finished the required data preprocessing, we can fit our AR-HMM to our computed datapoints. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for your model to successfully fit to the data, ensure you have the correct directory structure, such as the one below:\n",
    "\n",
    "<img src=\"media/model-dirstruct.png\" alt=\"Starting directory structure\" title=\"Starting Directory Structure\" />\n",
    "\n",
    "The bash command below will display the available options for model commands: count-frames, learn-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "moseq2-model --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the Model to the PC Scores\n",
    "\n",
    "Use the __moseq2-model__ tool to instantiate and train your model with the following bash command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd sample_session/\n",
    "moseq2-model learn-model _pca/pca_scores.h5 my_model.p"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The standard output of the above successfully executed command is below:\n",
    "\n",
    "Will only save the last iteration of the model\n",
    "Entering modeling training\n",
    "Found pcs in scores\n",
    "Setting kappa to the number of frames: 900\n",
    "Whitening the training data using the whiten_all function\n",
    "Using model class FastARWeakLimitStickyHDPHMM\n",
    "Adding data from key c3ae3048-ef47-4b61-846c-c4f6af9be953\n",
    "Saving pickle ./my_model.p                     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is of this command a generated trained AR-HMM pickle (compressed) file in your base directory of the recorded session (shown below).\n",
    "\n",
    "<img src=\"media/model-endstruct.png\" alt=\"Ending directory structure\" title=\"Final Directory Structure\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model with Free Parameters\n",
    "\n",
    "Below is a list of options/free parameters that users may configure to optimize their model fitting. __Most important free parameter is kappa__, which we typically set to the total number of frames in the dataset. That is, if you are modeling 2.56e6 frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "moseq2-model learn-model --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"media/model-flags.png\" title=\"Model Flag/Free Parameter List\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd sample_session/\n",
    "moseq2-model learn-model --kappa 2.5e6 _pca/pca_scores.h5 my_model.p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving Result Labels\n",
    "\n",
    "The __nlags__ parameter denotes the number of lags in the model frame prediction, therefore the model will prepend (a default of 3) negative label integer elements to account for the lagged frames.\n",
    "\n",
    "Each integer in the results list corresponds to a syllable label, except of course for the first **nlags** elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "results = joblib.load('sample_session/my_model.p')\n",
    "print(results['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Step: Visualize The Results\n",
    "\n",
    "Now that we have generated a fitted and tuned model, we can start visualizing our model's performance on crowd videos, among other metrics. [Click here to view the visualization walkthrough](http://localhost:8888/notebooks/MoSeq2_Step_5.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
