{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis: Visualization\n",
    "\n",
    "Finally we have some PC coefficients and scores, and a trained model.\n",
    "\n",
    "__(Note: in this walkthrough we will be using 2 different sessions in order to create \"crowd movies\")__.\n",
    "\n",
    "You will need ___more than one session recording___ in order to continue with this walkthrough.\n",
    "\n",
    "Consider the following directory structure:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".\n",
    "├── depth.dat\n",
    "├── depth_ts.txt\n",
    "├── metadata.json\n",
    "├── my_model.p\n",
    "├── example_extraction\n",
    "│   ├── bground.tiff\n",
    "│   ├── first_frame.tiff\n",
    "│   ├── results_00.h5\n",
    "│   ├── results_00.mp4\n",
    "│   ├── results_00.yaml\n",
    "│   └── roi_00.tiff\n",
    "├── proc\n",
    "│   ├── bground.tiff\n",
    "│   ├── first_frame.tiff\n",
    "│   ├── results_00.h5\n",
    "│   ├── results_00.mp4\n",
    "│   ├── results_00.yaml\n",
    "│   └── roi_00.tiff\n",
    "├── _pca\n",
    "│   ├── changepoints_dist.pdf\n",
    "│   ├── changepoints_dist.png\n",
    "│   ├── changepoints.h5\n",
    "│   ├── pca_components.pdf\n",
    "│   ├── pca_components.png\n",
    "│   ├── pca_scores.h5\n",
    "│   ├── pca_scree.pdf\n",
    "│   ├── pca_scree.png\n",
    "│   ├── pca.h5\n",
    "│   └── pca.yaml\n",
    "├── rgb.mp4\n",
    "└── rgb_ts.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Index File\n",
    "\n",
    "Using the __moseq2-viz__ tool, we can create an index file that will tell MoSeq2 where to find all the extractions and PCA results you wish to visualize.\n",
    "\n",
    "Below are the options provided by the moseq2-viz tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "moseq2-viz --help"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "For your reference, the options are pasted below:\n",
    "\n",
    "Usage: moseq2-viz [OPTIONS] COMMAND [ARGS]...\n",
    "\n",
    "Options:\n",
    "  --help  Show this message and exit.  [default: False]\n",
    "\n",
    "Commands:\n",
    "  add-group\n",
    "  copy-h5-metadata-to-yaml\n",
    "  generate-index\n",
    "  make-crowd-movies\n",
    "  plot-scalar-summary\n",
    "  plot-transition-graph\n",
    "  plot-usages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: in order to include all paths in the index file, run the following command one directory above the base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "moseq2-viz generate-index\n",
    "mv moseq2-index.yaml sample_session"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This will create a moseq2-index.yaml in your current directory. (Example shown below)\n",
    "\n",
    "files:\n",
    "- path:\n",
    "  - proc/results_00.h5\n",
    "  - proc/results_00.yaml\n",
    "  uuid: c3ae3048-ef47-4b61-846c-c4f6af9be953\n",
    "  group: default\n",
    "  metadata:\n",
    "    SubjectName: blackStockOFA80GritSanded_012517\n",
    "    SessionName: '012517'\n",
    "    NidaqChannels: 0\n",
    "    NidaqSamplingRate: 0.0\n",
    "    DepthResolution:\n",
    "    - 512\n",
    "    - 424\n",
    "    IsLittleEndian: true\n",
    "    DepthDataType: UInt16[]\n",
    "    ColorResolution:\n",
    "    - 512\n",
    "    - 424\n",
    "    ColorDataType: Byte[]\n",
    "    StartTime: '2017-01-25T10:42:07.1734698-05:00'\n",
    "- path:\n",
    "  - example_extraction/results_00.h5\n",
    "  - example_extraction/results_00.yaml\n",
    "  uuid: abe92017-1d40-495e-95ef-e420b7f0f4b9\n",
    "  group: default\n",
    "  metadata:\n",
    "    SubjectName: blackStockOFA80GritSanded_012517\n",
    "    SessionName: '012517'\n",
    "    NidaqChannels: 0\n",
    "    NidaqSamplingRate: 0.0\n",
    "    DepthResolution:\n",
    "    - 512\n",
    "    - 424\n",
    "    IsLittleEndian: true\n",
    "    DepthDataType: UInt16[]\n",
    "    ColorResolution:\n",
    "    - 512\n",
    "    - 424\n",
    "    ColorDataType: Byte[]\n",
    "    StartTime: '2017-01-25T10:42:07.1734698-05:00'\n",
    "pca_path: _pca/pca_scores.h5\n",
    "\n",
    "\n",
    "Note: the directories have been edited slightly so that the next command can execute while working in the base directory (with sample extraction as a subdirectory)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Crowd Movies\n",
    "This next command will enable you to generate \"crowd movies\" for your fit model; which are overlayed videos of your multiple recordings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "moseq2-viz make-crowd-movies moseq2-index.yaml my_model.p"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Below is the output you should see if the command was executed successfully.\n",
    "\n",
    "100%|██████████████████████████████████████████████████████████████████████████████| 40/40 [00:00<00:00, 1447.28it/s]\n",
    "100%|████████████████████████████████████████████████████████████████████████████████| 40/40 [00:06<00:00,  5.96it/s]\n",
    "\n",
    "Resulting in the following directory structure:\n",
    ".\n",
    "├── crowd_movies **\n",
    "│   ├── info.yaml **\n",
    "│   ├── syllable_sorted-id-0 (usage)_original-id-54.mp4 **\n",
    "│   ├── syllable_sorted-id-1 (usage)_original-id-29.mp4 **\n",
    "│   ├── syllable_sorted-id-2 (usage)_original-id-87.mp4 **\n",
    "│   ├── syllable_sorted-id-3 (usage)_original-id-7.mp4 **\n",
    "│   ├── syllable_sorted-id-4 (usage)_original-id-40.mp4 **\n",
    "│   ├── ... **\n",
    "│   ├── ... **\n",
    "│   └── syllable_sorted-id-39 (usage)_original-id-41.mp4 **\n",
    "├── depth.dat \n",
    "├── depth_ts.txt\n",
    "├── metadata.json\n",
    "├── my_model.p\n",
    "├── example_extraction\n",
    "│   ├── bground.tiff\n",
    "│   ├── first_frame.tiff\n",
    "│   ├── results_00.h5\n",
    "│   ├── results_00.mp4\n",
    "│   ├── results_00.yaml\n",
    "│   └── roi_00.tiff\n",
    "├── proc\n",
    "│   ├── bground.tiff\n",
    "│   ├── first_frame.tiff\n",
    "│   ├── results_00.h5\n",
    "│   ├── results_00.mp4\n",
    "│   ├── results_00.yaml\n",
    "│   └── roi_00.tiff\n",
    "├── _pca\n",
    "│   ├── changepoints_dist.pdf\n",
    "│   ├── changepoints_dist.png\n",
    "│   ├── changepoints.h5\n",
    "│   ├── pca_components.pdf\n",
    "│   ├── pca_components.png\n",
    "│   ├── pca_scores.h5\n",
    "│   ├── pca_scree.pdf\n",
    "│   ├── pca_scree.png\n",
    "│   ├── pca.h5\n",
    "│   └── pca.yaml\n",
    "├── rgb.mp4\n",
    "└── rgb_ts.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crowd Video Example\n",
    "\n",
    "Below is an example of a crowd video that you should see in your __crowd_movies/__ directory. It shows a number of mouse recordings overlayed into one clip, where a red dot appears on the mice for a split second indicating that all the mice in the recording have expressed the same syllable.\n",
    "<img src=\"media/crowd_movie.gif\" title=\"Crowd Movie\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Syllable Usages\n",
    "\n",
    "The following command will generate plots that display the syllable usage distributions that the trained model can detect from your recordings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd sample_session/\n",
    "moseq2-viz plot-usages moseq2-index.yaml my_model.p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Syllable Usage Plot\n",
    "Below is a plot that shows the probability that each syllable is being expressed; where the x-axis represents the syllables sorted by their label number, and the y-axis represents the probability value.\n",
    "<img src=\"media/usages_1.png\" title=\"Syllable Usages\" />\n",
    "\n",
    "#### Plotting Multiple Groups\n",
    "If you want to plot multiple groups, first you need to specify the groups in your index file. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "If you haven't specified any groups the contents might look like this:\n",
    "\n",
    "files:\n",
    "- path:\n",
    "  - proc/results_00.h5\n",
    "  - proc/results_00.yaml\n",
    "  uuid: c3ae3048-ef47-4b61-846c-c4f6af9be953\n",
    "  group: default\n",
    "  metadata:\n",
    "    SubjectName: blackStockOFA80GritSanded_012517\n",
    "    SessionName: '012517'\n",
    "    NidaqChannels: 0\n",
    "    NidaqSamplingRate: 0.0\n",
    "    DepthResolution:\n",
    "    - 512\n",
    "    - 424\n",
    "    IsLittleEndian: true\n",
    "    DepthDataType: UInt16[]\n",
    "    ColorResolution:\n",
    "    - 512\n",
    "    - 424\n",
    "    ColorDataType: Byte[]\n",
    "    StartTime: '2017-01-25T10:42:07.1734698-05:00'\n",
    "- path:\n",
    "  - example_extraction/results_00.h5\n",
    "  - example_extraction/results_00.yaml\n",
    "  uuid: abe92017-1d40-495e-95ef-e420b7f0f4b9\n",
    "  group: default\n",
    "  metadata:\n",
    "    SubjectName: blackStockOFA80GritSanded_012517\n",
    "    SessionName: '012517'\n",
    "    NidaqChannels: 0\n",
    "    NidaqSamplingRate: 0.0\n",
    "    DepthResolution:\n",
    "    - 512\n",
    "    - 424\n",
    "    IsLittleEndian: true\n",
    "    DepthDataType: UInt16[]\n",
    "    ColorResolution:\n",
    "    - 512\n",
    "    - 424\n",
    "    ColorDataType: Byte[]\n",
    "    StartTime: '2017-01-25T10:42:07.1734698-05:00'\n",
    "pca_path: _pca/pca_scores.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the metadata for each session, stored in metadata.json, comes in handy, since this is loaded into the metadata field for each file, which is now assigned a unique key (so if you move your data around we can keep track of it). Say you have recorded two sessions from two mice, each from a separate treatment group, which we'll call group1 and group2. \n",
    "\n",
    "You can use __moseq2-viz add-group__ to specify groups in the index.\n",
    "\n",
    "Note: make sure you enter the correct corresponding SubjectName.\n",
    "\n",
    "\n",
    "### Adding/Specifying Groups of Mice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd sample_session/\n",
    "moseq2-viz add-group -k SubjectName -v \"blackStockOFA80GritSanded_012517\" -g group1 moseq2-index.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MoSeq2-viz will search all of the sessions, and any sessions where the SubjectName is \"mouse1\" will be assigned to group1. If you made a mistake and you want to change the metadata for a particular session, you can modify the yaml file directory.\n",
    "\n",
    "If you have a list of values to add to a group, use the following syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "moseq2-viz add-group -k SubjectName -v \"mouse3\" -v \"mouse4\" -v \"mouse8\" -v \"mouse100\" -g \"groupd\" moseq2-index.yaml"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "If all goes well, this is what your moseq2-index.yaml should look like:\n",
    "\n",
    "files:\n",
    "- path:\n",
    "  - proc/results_00.h5\n",
    "  - proc/results_00.yaml\n",
    "  uuid: c3ae3048-ef47-4b61-846c-c4f6af9be953\n",
    "  group: group1\n",
    "  metadata:\n",
    "    SubjectName: blackStockOFA80GritSanded_012517\n",
    "    SessionName: '012517'\n",
    "    NidaqChannels: 0\n",
    "    NidaqSamplingRate: 0.0\n",
    "    DepthResolution:\n",
    "    - 512\n",
    "    - 424\n",
    "    IsLittleEndian: true\n",
    "    DepthDataType: UInt16[]\n",
    "    ColorResolution:\n",
    "    - 512\n",
    "    - 424\n",
    "    ColorDataType: Byte[]\n",
    "    StartTime: '2017-01-25T10:42:07.1734698-05:00'\n",
    "- path:\n",
    "  - example_extraction/results_00.h5\n",
    "  - example_extraction/results_00.yaml\n",
    "  uuid: abe92017-1d40-495e-95ef-e420b7f0f4b9\n",
    "  group: group2\n",
    "  metadata:\n",
    "    SubjectName: blackStockOFA80GritSanded_012517\n",
    "    SessionName: '012517'\n",
    "    NidaqChannels: 0\n",
    "    NidaqSamplingRate: 0.0\n",
    "    DepthResolution:\n",
    "    - 512\n",
    "    - 424\n",
    "    IsLittleEndian: true\n",
    "    DepthDataType: UInt16[]\n",
    "    ColorResolution:\n",
    "    - 512\n",
    "    - 424\n",
    "    ColorDataType: Byte[]\n",
    "    StartTime: '2017-01-25T10:42:07.1734698-05:00'\n",
    "pca_path: _pca/pca_scores.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Syllable Usages in Multiple Groups \n",
    "\n",
    "With the groups specified we can visualize things a few different ways. First, we can plot the syllable usages for each group (average and bootstrap confidence interval shown on a per session basis, i.e. one sample is one session):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd sample_session/\n",
    "moseq2-viz plot-usages moseq2-index.yaml my_model.p --group group1 --group group2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Scalars\n",
    "\n",
    "Next we can plot a scalar summary which includes information such as velocity and average height:\n",
    "\n",
    "You don't need to specify groups or a model here, by default each group is shown separately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2 [00:00<?, ?it/s]\r",
      "100%|██████████| 2/2 [00:00<00:00, 29.07it/s]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd sample_session/\n",
    "moseq2-viz plot-scalar-summary moseq2-index.yaml"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Below is the output you should see if the command was executed successfully.\n",
    "\n",
    "100%|██████████| 2/2 [00:00<00:00, 29.07it/s]\n",
    "\n",
    "Resulting in the following directory structure and plots respectively.\n",
    "\n",
    ".\n",
    "├── crowd_movies \n",
    "│   ├── info.yaml \n",
    "│   ├── syllable_sorted-id-0 (usage)_original-id-54.mp4 \n",
    "│   ├── syllable_sorted-id-1 (usage)_original-id-29.mp4 \n",
    "│   ├── syllable_sorted-id-2 (usage)_original-id-87.mp4 \n",
    "│   ├── syllable_sorted-id-3 (usage)_original-id-7.mp4 \n",
    "│   ├── syllable_sorted-id-4 (usage)_original-id-40.mp4 \n",
    "│   ├── ... \n",
    "│   ├── ... \n",
    "│   └── syllable_sorted-id-39 (usage)_original-id-41.mp4 \n",
    "├── depth.dat \n",
    "├── depth_ts.txt\n",
    "├── metadata.json\n",
    "├── my_model.p\n",
    "├── example_extraction\n",
    "│   ├── bground.tiff\n",
    "│   ├── first_frame.tiff\n",
    "│   ├── results_00.h5\n",
    "│   ├── results_00.mp4\n",
    "│   ├── results_00.yaml\n",
    "│   └── roi_00.tiff\n",
    "├── proc\n",
    "│   ├── bground.tiff\n",
    "│   ├── first_frame.tiff\n",
    "│   ├── results_00.h5\n",
    "│   ├── results_00.mp4\n",
    "│   ├── results_00.yaml\n",
    "│   └── roi_00.tiff\n",
    "├── scalars_position.png **\n",
    "├── scalars_position.pdf **\n",
    "├── scalars_summary.png **\n",
    "├── scalars_summary.pdf **\n",
    "├── _pca\n",
    "│   ├── changepoints_dist.pdf\n",
    "│   ├── changepoints_dist.png\n",
    "│   ├── changepoints.h5\n",
    "│   ├── pca_components.pdf\n",
    "│   ├── pca_components.png\n",
    "│   ├── pca_scores.h5\n",
    "│   ├── pca_scree.pdf\n",
    "│   ├── pca_scree.png\n",
    "│   ├── pca.h5\n",
    "│   └── pca.yaml\n",
    "├── rgb.mp4\n",
    "└── rgb_ts.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalars Summary Plot\n",
    "\n",
    "<img src=\"media/scalars_summary.png\" title=\"Scalars Summary Plot\" />\n",
    "\n",
    "\n",
    "### Scalars Position (Tracking) Plot\n",
    "<img src=\"media/scalars_position.png\" title=\"Scalars Position Tracking Plot\" />\n",
    "\n",
    "\n",
    "__Note that both graphs are the same because they represent the same session. This is only for walkthrough demonstration purposes.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Transition Graphs\n",
    "\n",
    "Finally, we can visualize the transition graphs and their differences with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting labels...\n",
      "Computing transition matrices...\n",
      "Creating plot...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aymanzeine/anaconda3/envs/moseq2/lib/python3.6/site-packages/networkx/drawing/nx_pylab.py:579: MatplotlibDeprecationWarning: \n",
      "The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead.\n",
      "  if not cb.iterable(width):\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd sample_session/\n",
    "moseq2-viz plot-transition-graph moseq2-index.yaml my_model.p --group group1 --group group2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you only have one group to graph, this is what the transition plot will look like:\n",
    "\n",
    "### Transition Graph for One Group\n",
    "<img src=\"media/transitions.png\" title=\"Transition Graph\" />\n",
    "\n",
    "### Transition Graph for Difference Between Two Groups\n",
    "__Coming soon__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin Syllable Statistical Testing\n",
    "\n",
    "Now that we are done visualizing all of our data and results, we can start performing statistical analysis on the model's performance on unseen test data. [Click here for the Statistical Analysis walkthrough](http://localhost:8888/notebooks/MoSeq2_Step_6.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
